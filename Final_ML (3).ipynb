{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMBJxgSe7uGN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType, DoubleType\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, StringType\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassificationModel\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "id": "1z3HNErE75zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def negative_check(value1, value2):\n",
        "    try:\n",
        "        # Ensure both values are strings and contain a negative sign before converting\n",
        "        if not (str(value1).strip().startswith('-') or str(value2).strip().startswith('-')):\n",
        "            return False\n",
        "\n",
        "        # Convert values to float and compare their absolute values\n",
        "        num1 = float(value1)\n",
        "        num2 = float(value2)\n",
        "        return abs((abs(num1)- abs(num2)))<1\n",
        "    except ValueError:\n",
        "        # Return False if there's an error converting to float (e.g., if the input is not numeric)\n",
        "        return False\n",
        "\n",
        "# Test cases\n",
        "print(negative_check(\"-5\", \"-6.0\"))  # True\n",
        "print(negative_check(\"-10\", \"-10\"))  # True\n",
        "print(negative_check(\"-5\", \"5\"))     # False\n",
        "print(negative_check(\"5\", \"-5\"))     # False\n",
        "print(negative_check(\"-3.2\", \"-3.2\"))# True\n",
        "print(negative_check(\"-3.2\", \"abc\")) # False\n",
        "print(negative_check(\"5\", \"5\"))      # False\n",
        "print(negative_check(\"0\", \"-0\"))     # False"
      ],
      "metadata": {
        "id": "Yn6uolHG755j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leading_zero_check(value1, value2):\n",
        "    try:\n",
        "        # Strip leading zeros and convert to float to ignore trailing zeros\n",
        "        normalized_value1 = float(value1.lstrip('0') or '0')\n",
        "        normalized_value2 = float(value2.lstrip('0') or '0')\n",
        "\n",
        "        # Check if there were leading zeros\n",
        "        had_leading_zeros = (value1.lstrip('0') != value1 and len(value1.strip('0')) > 0) or \\\n",
        "                            (value2.lstrip('0') != value2 and len(value2.strip('0')) > 0)\n",
        "\n",
        "        # Check if values are equal after normalization\n",
        "        are_equal = normalized_value1 == normalized_value2\n",
        "\n",
        "        # Return True only if there are leading zeros and values are equal\n",
        "        return are_equal and had_leading_zeros\n",
        "    except ValueError:\n",
        "        # Handle cases where conversion to float fails\n",
        "        return False\n",
        "\n",
        "# Example usage:\n",
        "value1 = \"123.0\"\n",
        "value2 = \"0123\"\n",
        "are_equal = leading_zero_check(value1, value2)\n",
        "print(\"Are equal after removing leading zeros:\", are_equal)\n"
      ],
      "metadata": {
        "id": "mtYNV7rG76sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def is_scientific_notation(value1, value2):\n",
        "    \"\"\"\n",
        "    Checks if either value1 or value2 is in scientific notation.\n",
        "    If either is in scientific notation, it verifies if the absolute difference is < 1.\n",
        "\n",
        "    Returns:\n",
        "        - True if scientific notation exists and the difference < 1.\n",
        "        - False otherwise.\n",
        "    \"\"\"\n",
        "    # Regular expression for scientific notation\n",
        "    sci_notation_regex = r\"^-?\\d+(\\.\\d+)?[eE][-+]?\\d+$\"\n",
        "\n",
        "    # Convert to string and remove spaces\n",
        "    value1, value2 = str(value1).strip(), str(value2).strip()\n",
        "\n",
        "    # Check if either value is in scientific notation\n",
        "    is_sci1 = bool(re.match(sci_notation_regex, value1))\n",
        "    is_sci2 = bool(re.match(sci_notation_regex, value2))\n",
        "\n",
        "    # If neither value is in scientific notation, return False\n",
        "    if not is_sci1 and not is_sci2:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Convert both values to float for comparison\n",
        "        num1, num2 = float(value1), float(value2)\n",
        "\n",
        "        # Check if absolute difference is less than 1\n",
        "        return abs(abs(num1) - abs(num2)) < 1\n",
        "\n",
        "    except ValueError:\n",
        "        # If conversion fails, return False (invalid input)\n",
        "        return False\n",
        "\n",
        "# Example Tests\n",
        "print(is_scientific_notation(\"1.23e3\", \"1230\"))  # Expected: True (difference < 1)\n",
        "print(is_scientific_notation(\"4.5E-3\", \"0.0045\"))  # Expected: True (difference < 1)\n",
        "print(is_scientific_notation(\"2E5\", \"200001\"))  # Expected: False (difference > 1)\n",
        "print(is_scientific_notation(\"12345\", \"1.2345e4\"))  # Expected: True (difference < 1)\n",
        "print(is_scientific_notation(\"1.23E4\", \"1.24E4\"))  # Expected: False (difference > 1)\n",
        "print(is_scientific_notation(\"-1.23e3\", \"1230\"))  # Expected: True (ignores sign difference)\n",
        "print(is_scientific_notation(\"-4.5E-3\", \"-0.0045\"))  # Expected: True (ignores sign difference)\n",
        "print(is_scientific_notation(\"1E2\", \"-100\"))  # Expected: True (ignores sign, difference < 1)\n",
        "print(is_scientific_notation(\"abc\", \"1.23e3\"))  # Expected: False (invalid input)\n"
      ],
      "metadata": {
        "id": "ZvnPXPkz76ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from decimal import Decimal\n",
        "\n",
        "def normalize_number_string(s):\n",
        "    \"\"\"Normalize a number string by removing thousand separators and handling decimal points.\"\"\"\n",
        "    # Remove common thousand separators (commas, spaces, or periods depending on locale)\n",
        "    s = re.sub(r'[,\\s]', '', s)\n",
        "    return s\n",
        "\n",
        "def thousand_separator_difference(value1, value2):\n",
        "\n",
        "    \"\"\"\n",
        "    Determine if two number strings differ only by the presence of thousand separators.\n",
        "\n",
        "    Args:\n",
        "    value1 (str): First number string, potentially with thousand separators.\n",
        "    value2 (str): Second number string, potentially with thousand separators.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if numbers differ only by separators, False otherwise.\n",
        "    \"\"\"\n",
        "    normalized1 = normalize_number_string(value1)\n",
        "    normalized2 = normalize_number_string(value2)\n",
        "\n",
        "    try:\n",
        "        # Convert both to Decimal to check numerical equivalence\n",
        "        num1 = Decimal(normalized1)\n",
        "        num2 = Decimal(normalized2)\n",
        "    except:\n",
        "        return False  # Return False if either number is not a valid number format\n",
        "\n",
        "    if num1 == num2:\n",
        "        # If numerically equal, check if original strings were different (thus only separator difference)\n",
        "        return value1 != value2\n",
        "    return False\n",
        "\n",
        "# Example usage:\n",
        "print(thousand_separator_difference(\"1,234,567\", \"123 4567\"))  # True\n",
        "print(thousand_separator_difference(\"1 234 567\", \"12345 67\"))  # True\n",
        "print(thousand_separator_difference(\"1.234.567\", \"1234567\"))  # True in locales where '.' is a thousand separator\n",
        "print(thousand_separator_difference(\"1,234,567\", \"1234,567\")) # False, different number placements\n"
      ],
      "metadata": {
        "id": "UYFRMSCr764v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def are_numbers_effectively_equal(num1, num2, tolerance=1.0):\n",
        "  # Check if there were leading zeros\n",
        "    had_leading_zeros = (num1.lstrip('0') != num1 and len(num1.strip('0')) > 0) or \\\n",
        "                            (num2.lstrip('0') != num2 and len(num2.strip('0')) > 0)\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Attempt to convert inputs to floats\n",
        "        num1 = float(num1)\n",
        "        num2 = float(num2)\n",
        "\n",
        "        # Calculate the absolute difference\n",
        "        difference = abs(num1 - num2)\n",
        "\n",
        "        # Compare the difference with the tolerance\n",
        "        are_equal = difference < tolerance\n",
        "        # Return True only if there are leading zeros and values are equal\n",
        "        return are_equal != had_leading_zeros\n",
        "    except ValueError:\n",
        "        # Return False if there is an error converting inputs to float\n",
        "        return False\n",
        "\n",
        "# Example usage with possible non-numeric inputs:\n",
        "result1 = are_numbers_effectively_equal(\"100\", \"100\")\n",
        "result2 = are_numbers_effectively_equal(\"abc\", \"100.5\")\n",
        "print(\"Are the numbers effectively equal?\", result1)  # Expected: True\n",
        "print(\"Is the input valid?\", result2)  # Expected: False, because 'abc' cannot be converted to float\n",
        "\n"
      ],
      "metadata": {
        "id": "iH-adN6Y76-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "currency_mappings = {\n",
        "    \"$\": [\"USD\", \"US DOLLAR\", \"US DOLLARS\", \"DOLLAR\", \"DOLLARS\", \"$\"],\n",
        "    \"€\": [\"EUR\", \"EURO\", \"EUROS\", \"€\"],\n",
        "    \"£\": [\"GBP\", \"POUND STERLING\", \"POUND\", \"POUNDS\", \"£\"],\n",
        "    \"¥\": [\"JPY\", \"YEN\", \"¥\"],\n",
        "    \"₹\": [\"INR\", \"INDIAN RUPEE\", \"RUPEE\", \"RUPEES\", \"₹\"],\n",
        "    \"₺\": [\"TRY\", \"TURKISH LIRA\", \"LIRA\", \"₺\"],\n",
        "    \"₩\": [\"KRW\", \"SOUTH KOREAN WON\", \"KOREAN WON\", \"₩\"],\n",
        "    \"₦\": [\"NGN\", \"NIGERIAN NAIRA\", \"NAIRA\", \"₦\"],\n",
        "    \"₴\": [\"UAH\", \"UKRAINIAN HRYVNIA\", \"HRYVNIA\", \"₴\"],\n",
        "    \"₽\": [\"RUB\", \"RUSSIAN RUBLE\", \"RUBLE\", \"₽\"],\n",
        "}\n",
        "\n",
        "def extract_currency_and_value(value):\n",
        "    \"\"\"\n",
        "    Extracts the currency type and numerical value from a given string.\n",
        "    Returns:\n",
        "      - (currency, numeric_value) tuple if currency is found.\n",
        "      - (None, None) if no currency is found.\n",
        "    \"\"\"\n",
        "    value_clean = value.upper().replace(\" \", \"\").replace(\",\", \"\")  # Normalize case, remove spaces & commas\n",
        "    extracted_currency = None\n",
        "\n",
        "    # Extract numerical part (allowing negative numbers)\n",
        "    numeric_part = re.findall(r\"[-+]?\\d*\\.?\\d+\", value_clean)  # Extract numbers\n",
        "    numeric_value = numeric_part[0] if numeric_part else None  # Get the first extracted number\n",
        "\n",
        "    # Identify currency type\n",
        "    for currency_symbol, keywords in currency_mappings.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in value_clean:\n",
        "                extracted_currency = currency_symbol  # Assign the standard symbol\n",
        "                break\n",
        "        if extracted_currency:\n",
        "            break  # Stop loop if currency found\n",
        "\n",
        "    # If no currency is found, return (None, None)\n",
        "    if not extracted_currency:\n",
        "        return None, None\n",
        "\n",
        "    return extracted_currency, numeric_value\n",
        "\n",
        "def detect_currency(value1, value2):\n",
        "    \"\"\"\n",
        "    Compares two currency values:\n",
        "      - Returns True if both values match in currency type and numeric value.\n",
        "      - Returns False if there's a mismatch in currency type or numeric value.\n",
        "      - Returns 0 if neither value contains a currency reference (meaning we don’t check it).\n",
        "    \"\"\"\n",
        "    currency1, num1 = extract_currency_and_value(value1)\n",
        "    currency2, num2 = extract_currency_and_value(value2)\n",
        "\n",
        "    # If neither value has a currency, return 0 (ignore non-currency cases)\n",
        "    if currency1 is None and currency2 is None:\n",
        "        return False\n",
        "\n",
        "    # If one has a currency and the other doesn't, return False (they are different)\n",
        "    if (currency1 is not None and currency2 is None) or (currency2 is not None and currency1 is None):\n",
        "        return False\n",
        "\n",
        "    # If currency types don't match, return False\n",
        "    if currency1 != currency2:\n",
        "        return False\n",
        "\n",
        "    # If both values have the same currency but different numbers, return False\n",
        "    if num1 != num2:\n",
        "        return False\n",
        "\n",
        "    return True  # Both currency type and numeric values match\n",
        "\n",
        "# Example Tests\n",
        "print(\"Match between -100 and 100:\", detect_currency(\"-100\", \"100\"))  # Expected: 0 (No currency, ignore)\n",
        "print(\"Match between € 50 and 50 EUR:\", detect_currency(\"€ 50\", \"50 EUR\"))  # Expected: True (Same currency, same value)\n",
        "print(\"Match between 100 INR and 100:\", detect_currency(\"100 INR\", \"100\"))  # Expected: False (One has currency, one doesn't)\n",
        "print(\"Match between 500 and 500:\", detect_currency(\"500\", \"500\"))  # Expected: 0 (No currency, ignore)\n",
        "print(\"Match between $100 and 100USD:\", detect_currency(\"$ 100\", \"100 USD\"))  # Expected: True (Same currency, same value)\n",
        "print(\"Match between 100$ and 150$:\", detect_currency(\"100$\", \"150$\"))  # Expected: False (Same currency, different value)\n",
        "print(\"Match between 200 GBP and 200 USD:\", detect_currency(\"200 GBP\", \"200 USD\"))  # Expected: False (Different currency)\n",
        "print(\"Match between $3,487.14 and 3487.14 $:\", detect_currency(\"$3,487.14\", \"3487.14 $\"))  # Expected: True (Same currency, same value)\n"
      ],
      "metadata": {
        "id": "bY-rRBp377CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from decimal import Decimal\n",
        "\n",
        "def scientific_notation_with_tolerance(value1, value2, tolerance=1):\n",
        "    \"\"\"\n",
        "    Compares two values after checking if either is in scientific notation. If true,\n",
        "    compares their difference to a specified tolerance.\n",
        "\n",
        "    Args:\n",
        "    value1, value2 (str): Strings representing the numbers, where one might be in scientific notation.\n",
        "    tolerance (float): The maximum absolute difference allowed to consider the numbers equivalent.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the numbers are considered equivalent within the given tolerance, False otherwise.\n",
        "    \"\"\"\n",
        "    # Regular expression to detect scientific notation\n",
        "    sci_notation_regex = r'^-?\\d+(\\.\\d+)?[eE][-+]?\\d+$'\n",
        "\n",
        "    # Check if either value is in scientific notation\n",
        "    if re.match(sci_notation_regex, value1) or re.match(sci_notation_regex, value2):\n",
        "        try:\n",
        "            # Convert both values to Decimal for precision\n",
        "            num1 = Decimal(value1.strip())\n",
        "            num2 = Decimal(value2.strip())\n",
        "\n",
        "            # Calculate the absolute difference\n",
        "            difference = abs(abs(num1) - abs(num2))\n",
        "\n",
        "            # Print the comparison details for debugging\n",
        "            print(f\"Comparing {num1} to {num2}, difference: {difference}\")\n",
        "\n",
        "            # Determine if the difference is within the allowed tolerance\n",
        "            return difference < Decimal(tolerance)\n",
        "        except Exception as e:\n",
        "            # Handle conversion errors and other exceptions\n",
        "            print(f\"Error during conversion or calculation: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        # If neither value is in scientific notation, return False\n",
        "        return False\n",
        "\n",
        "# Example usage:\n",
        "print(scientific_notation_with_tolerance(\"-5.6145711E+07\", \"56145711.73\", tolerance=1))  # Expected: True\n",
        "print(scientific_notation_with_tolerance(\"2.98E+07\", \"29847591.85\", tolerance=1))  # Expected: True\n",
        "print(scientific_notation_with_tolerance(\"9.50E+07\", \"95006862.32\", tolerance=1))  # Expected: True\n"
      ],
      "metadata": {
        "id": "ygwnMLAQ9ZNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, when, lit\n",
        "from pyspark.sql.types import StringType, BooleanType, IntegerType\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"Data Classification\").getOrCreate()\n",
        "\n",
        "# Load data\n",
        "df = spark.read.csv(\"/content/Final_ML.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Define the UDFs and ensure they return Boolean\n",
        "is_scientific_notation_udf = udf(scientific_notation_with_tolerance, BooleanType())\n",
        "thousand_separator_difference_udf = udf(thousand_separator_difference, BooleanType())\n",
        "leading_zero_check_udf = udf(leading_zero_check, BooleanType())\n",
        "are_numbers_effectively_equal_udf = udf(are_numbers_effectively_equal, BooleanType())\n",
        "detect_currency_udf = udf(detect_currency, BooleanType())\n",
        "negative_check_udf = udf(negative_check, BooleanType())\n",
        "\n",
        "# Convert Boolean outputs to Integer (1 if True, 0 if False)\n",
        "df = df.withColumn(\"Scientific_Notation\", when(is_scientific_notation_udf(col(\"Source\"), col(\"Destination\")) == True, 1).otherwise(0))\n",
        "df = df.withColumn(\"Thousand_Separator\", when(thousand_separator_difference_udf(col(\"Source\"), col(\"Destination\")) == True, 1).otherwise(0))\n",
        "df = df.withColumn(\"Rounded_Off\", when(are_numbers_effectively_equal_udf(col(\"Source\"), col(\"Destination\")) == True, 1).otherwise(0))\n",
        "df = df.withColumn(\"Leading_Zero\", when(leading_zero_check_udf(col(\"Source\"), col(\"Destination\")) == True, 1).otherwise(0))\n",
        "df = df.withColumn(\"Currency_Diff\", when(detect_currency_udf(col(\"Source\"), col(\"Destination\")) == True, 1).otherwise(0))\n",
        "df = df.withColumn(\"Negative_Check\", when(negative_check_udf(col(\"Source\"), col(\"Destination\")) == True, 1).otherwise(0))\n",
        "\n",
        "# Create the `Discrepancy_Type` column based on function outputs\n",
        "df = df.withColumn(\n",
        "    \"Discrepancy_Type\",\n",
        "    when(col(\"Scientific_Notation\") == 1, \"Scientific Notation Difference\")\n",
        "    .when(col(\"Thousand_Separator\") == 1, \"Thousand Separator Difference\")\n",
        "    .when(col(\"Rounded_Off\") == 1, \"Rounded Off\")\n",
        "    .when(col(\"Leading_Zero\") == 1, \"Leading Zero Issue\")\n",
        "    .when(col(\"Currency_Diff\") == 1, \"Currency Symbol Difference\")\n",
        "    .when(col(\"Negative_Check\") == 1, \"Numbers are the same but one is negative\")\n",
        "    .otherwise(\"No discrepancy\")\n",
        ")\n",
        "\n",
        "# Show results and save to CSV\n",
        "df.show()\n",
        "# df.write.csv(\"/path/to/save/classified_data.csv\", header=True)\n",
        "\n",
        "# Stop Spark session\n",
        "# spark.stop()\n"
      ],
      "metadata": {
        "id": "DfnvQPEP77N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Case_Sensitive_Score\", lit(0).cast('integer'))\n",
        "df = df.withColumn(\"Case_Insensitive_Score\", lit(0).cast('integer'))\n",
        "df = df.withColumn(\"Case_Sensitivity_Diff\", lit(0).cast('integer'))\n",
        "df = df.withColumn(\"Special_Character_Score\", lit(0).cast('integer'))\n",
        "df = df.withColumn(\"Special_Character_Diff\", lit(0).cast('integer'))\n",
        "df = df.withColumn(\"Space_diff\", lit(0).cast('integer'))\n",
        "df = df.withColumn(\"space_score\", lit(0).cast('integer'))"
      ],
      "metadata": {
        "id": "HMhPw6Kp77Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "id": "vXwIkJXD77Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fuzzy matching functions\n",
        "def get_fuzzy_scores(str1, str2):\n",
        "    \"\"\" Compute various fuzzy matching scores between two strings. \"\"\"\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    str1_clean, str2_clean = re.sub(r'[^\\w\\s]', '', str1), re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    str1_space_norm, str2_space_norm = ' '.join(str1.split()), ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)\n",
        "\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = abs(case_sensitive_score - token_score)\n",
        "\n",
        "    return (case_sensitive_score, case_insensitive_score, case_sensitivity_diff,\n",
        "            special_char_score,special_char_diff, space_diff,space_score, abbreviation_diff)\n",
        "\n",
        "# Register UDFs\n",
        "fuzzy_udf = udf(lambda str1, str2: get_fuzzy_scores(str1, str2),\"array<double>\")\n",
        "\n",
        "# Apply fuzzy matching functions\n",
        "df = df.withColumn(\"Fuzzy Scores\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))\n",
        "\n",
        "# Extract individual scores\n",
        "df = df.withColumn(\"Case_Sensitive_Score\", col(\"Fuzzy Scores\")[0]) \\\n",
        "                       .withColumn(\"Case_Insensitive_Score\", col(\"Fuzzy Scores\")[1]) \\\n",
        "                       .withColumn(\"Case_Sensitivity_Diff\", col(\"Fuzzy Scores\")[2]) \\\n",
        "                       .withColumn(\"Special_Character_Score\", col(\"Fuzzy Scores\")[3]) \\\n",
        "                       .withColumn(\"Special_Character_Diff\", col(\"Fuzzy Scores\")[4]) \\\n",
        "                       .withColumn(\"Space_diff\", col(\"Fuzzy Scores\")[5]) \\\n",
        "                       .withColumn(\"space_score\", col(\"Fuzzy Scores\")[6]) \\\n",
        "                       .drop(\"Fuzzy Scores\")\n",
        "                      #  .withColumn(\"Abbreviation Diff\", col(\"Fuzzy Scores\")[5]) \\"
      ],
      "metadata": {
        "id": "StUiJYUS77Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the csv file\n",
        "df.toPandas().to_csv('FuzzyMatching_Final.csv', index=False)"
      ],
      "metadata": {
        "id": "CVm5hgG177ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8UExWJsCKLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(1)"
      ],
      "metadata": {
        "id": "mSOw2Y8i77dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop th column Discrepancy_Type\n",
        "df = df.drop(\"Discrepancy_Type\")"
      ],
      "metadata": {
        "id": "1wcJ3Jsi77hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"Label\").distinct().show(truncate=False)"
      ],
      "metadata": {
        "id": "A6vu-OBk77j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(inputCol=\"Label\", outputCol=\"Label_Index\")\n",
        "model_indexer = indexer.fit(df)\n",
        "df_pyspark = model_indexer.transform(df)"
      ],
      "metadata": {
        "id": "J8rzT7JRMVza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = model_indexer.labels\n",
        "# Print out the index to label mapping\n",
        "print(\"Index to Label Mapping:\")\n",
        "for idx, label in enumerate(labels):\n",
        "    print(f\"Index {idx} corresponds to label '{label}'\")"
      ],
      "metadata": {
        "id": "fZ_fbV6lMV2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "6sBKbWjXMV8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features\n",
        "feature_columns = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',\n",
        " 'Case_Sensitive_Score',\n",
        " 'Case_Insensitive_Score',\n",
        " 'Case_Sensitivity_Diff',\n",
        " 'Special_Character_Score',\n",
        " 'Special_Character_Diff',\n",
        " 'Space_diff',\n",
        " 'space_score',]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
      ],
      "metadata": {
        "id": "bsrNIzlfBco7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to cast\n",
        "columns_to_cast = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',\n",
        " 'Case_Sensitive_Score',\n",
        " 'Case_Insensitive_Score',\n",
        " 'Case_Sensitivity_Diff',\n",
        " 'Special_Character_Score',\n",
        " 'Special_Character_Diff',\n",
        " 'Space_diff',\n",
        " 'space_score']\n",
        "\n",
        "# Cast each column to Integer\n",
        "for col_name in columns_to_cast:\n",
        "    df_pyspark = df_pyspark.withColumn(col_name, col(col_name).cast(\"int\"))"
      ],
      "metadata": {
        "id": "p85jt7CVMV_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = assembler.transform(df_pyspark)"
      ],
      "metadata": {
        "id": "JVF57d7vMWFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show(5)"
      ],
      "metadata": {
        "id": "FeCE3IUSDh6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "train_data, test_data = df_pyspark.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "cTHwAV7gMWLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the classifier (Random Forest)\n",
        "rf_classifier = RandomForestClassifier(labelCol=\"Label_Index\", featuresCol=\"features\", numTrees=50)\n",
        "model = rf_classifier.fit(train_data)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model using accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Label_Index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"✅ Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save trained model\n",
        "model.save(\"FuzzyMatching_RF_Model_3\")\n",
        "print(\"✅ Model saved successfully!\")"
      ],
      "metadata": {
        "id": "hMYssp2OMWOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features\n",
        "feature_columns = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',\n",
        " 'Case_Sensitive_Score',\n",
        " 'Case_Insensitive_Score',\n",
        " 'Case_Sensitivity_Diff',\n",
        " 'Special_Character_Score',\n",
        " 'Special_Character_Diff',\n",
        " 'Space_diff',\n",
        " 'space_score',]\n",
        "\n",
        "# List of columns to cast\n",
        "columns_to_cast = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',\n",
        " 'Case_Sensitive_Score',\n",
        " 'Case_Insensitive_Score',\n",
        " 'Case_Sensitivity_Diff',\n",
        " 'Special_Character_Score',\n",
        " 'Special_Character_Diff',\n",
        " 'Space_diff',\n",
        " 'space_score']\n",
        "\n",
        "# Cast each column to Integer\n",
        "for col_name in columns_to_cast:\n",
        "    df_pyspark = df_pyspark.withColumn(col_name, col(col_name).cast(\"int\"))\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df_pyspark = assembler.transform(df_pyspark)"
      ],
      "metadata": {
        "id": "NYEpemwNXPxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register UDFs\n",
        "fuzzy_udf = udf(lambda str1, str2: get_fuzzy_scores(str1, str2),\"array<double>\")"
      ],
      "metadata": {
        "id": "_311m1ZXXP0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input words\n",
        "# word1 = \"srinvas\"\n",
        "# word2 = \"sr invas\"\n",
        "\n",
        "# Convert input into DataFrame for prediction\n",
        "df_input = spark.createDataFrame([(word1, word2)], [\"Source\", \"Destination\"])\n",
        "df_input = df_input.withColumn(\"Fuzzy Scores\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))\n",
        "# Extract individual scores\n",
        "df_input = df_input.withColumn(\"Case_Sensitive_Score\", col(\"Fuzzy Scores\")[0]) \\\n",
        "                       .withColumn(\"Case_Insensitive_Score\", col(\"Fuzzy Scores\")[1]) \\\n",
        "                       .withColumn(\"Case_Sensitivity_Diff\", col(\"Fuzzy Scores\")[2]) \\\n",
        "                       .withColumn(\"Special_Character_Score\", col(\"Fuzzy Scores\")[3]) \\\n",
        "                       .withColumn(\"Special_Character_Diff\", col(\"Fuzzy Scores\")[4]) \\\n",
        "                       .withColumn(\"Space_diff\", col(\"Fuzzy Scores\")[5]) \\\n",
        "                       .withColumn(\"space_score\", col(\"Fuzzy Scores\")[6]) \\\n",
        "                       .drop(\"Fuzzy Scores\")\n",
        "                      #  .withColumn(\"Abbreviation Diff\", col(\"Fuzzy Scores\")[5]) \\\n",
        "# Apply other UDFs\n",
        "df_input = df_input.withColumn(\"Scientific_Notation\", is_scientific_notation_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Thousand_Separator\", thousand_separator_difference_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Leading_Zero\", leading_zero_check_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Rounded_Off\", are_numbers_effectively_equal_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Currency_Diff\", detect_currency_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Negative_Check\", negative_check_udf(col(\"Source\"), col(\"Destination\")))\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Convert Boolean columns to integer\n",
        "columns_to_convert = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',]\n",
        "for column in columns_to_convert:\n",
        "    df_input = df_input.withColumn(column, when(col(column), 1).otherwise(0))\n",
        "\n",
        "# Select relevant features\n",
        "feature_columns = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',\n",
        " 'Case_Sensitive_Score',\n",
        " 'Case_Insensitive_Score',\n",
        " 'Case_Sensitivity_Diff',\n",
        " 'Special_Character_Score',\n",
        " 'Special_Character_Diff',\n",
        " 'Space_diff',\n",
        " 'space_score',]\n",
        "\n",
        "# List of columns to cast\n",
        "columns_to_cast = ['Scientific_Notation',\n",
        " 'Thousand_Separator',\n",
        " 'Rounded_Off',\n",
        " 'Leading_Zero',\n",
        " 'Currency_Diff',\n",
        " 'Negative_Check',\n",
        " 'Case_Sensitive_Score',\n",
        " 'Case_Insensitive_Score',\n",
        " 'Case_Sensitivity_Diff',\n",
        " 'Special_Character_Score',\n",
        " 'Special_Character_Diff',\n",
        " 'Space_diff',\n",
        " 'space_score']\n",
        "\n",
        "# Cast each column to Integer\n",
        "for col_name in columns_to_cast:\n",
        "    df_input = df_input.withColumn(col_name, col(col_name).cast(\"int\"))\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df_input = assembler.transform(df_input)"
      ],
      "metadata": {
        "id": "jiF1HzNnaGnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word1 = \"srinivas\"\n",
        "word2 = \"sr in iva\""
      ],
      "metadata": {
        "id": "t48Xn4PcgIu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "prediction = model.transform(df_input).select(\"prediction\").collect()[0][0]\n",
        "prediction\n"
      ],
      "metadata": {
        "id": "76_0OWLzXQGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Index 0 corresponds to label 'Case Sensitivity'\n",
        "Index 1 corresponds to label 'Extra Space Issues'\n",
        "Index 2 corresponds to label 'Special Character Differences'\n",
        "Index 3 corresponds to label 'Rounded Off Numbers'\n",
        "Index 4 corresponds to label 'Currency Symbol Difference'\n",
        "Index 5 corresponds to label 'Leading Zero Issue'\n",
        "Index 6 corresponds to label 'Negative vs Positive'\n",
        "Index 7 corresponds to label 'Scientific Notation Difference'\n",
        "Index 8 corresponds to label 'Thousands Separator Difference'\n",
        "Index 9 corresponds to label 'No Match'"
      ],
      "metadata": {
        "id": "D6USiVnPYDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features(word1, word2):\n",
        "  from pyspark.sql.functions import col\n",
        "    # Example input words\n",
        "  # word1 = \"srinvas\"\n",
        "  # word2 = \"sr invas\"\n",
        "\n",
        "  # Convert input into DataFrame for prediction\n",
        "  df_input = spark.createDataFrame([(word1, word2)], [\"Source\", \"Destination\"])\n",
        "  df_input = df_input.withColumn(\"Fuzzy Scores\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  # Extract individual scores\n",
        "  df_input = df_input.withColumn(\"Case_Sensitive_Score\", col(\"Fuzzy Scores\")[0]) \\\n",
        "                        .withColumn(\"Case_Insensitive_Score\", col(\"Fuzzy Scores\")[1]) \\\n",
        "                        .withColumn(\"Case_Sensitivity_Diff\", col(\"Fuzzy Scores\")[2]) \\\n",
        "                        .withColumn(\"Special_Character_Score\", col(\"Fuzzy Scores\")[3]) \\\n",
        "                        .withColumn(\"Special_Character_Diff\", col(\"Fuzzy Scores\")[4]) \\\n",
        "                        .withColumn(\"Space_diff\", col(\"Fuzzy Scores\")[5]) \\\n",
        "                        .withColumn(\"space_score\", col(\"Fuzzy Scores\")[6]) \\\n",
        "                        .drop(\"Fuzzy Scores\")\n",
        "                        #  .withColumn(\"Abbreviation Diff\", col(\"Fuzzy Scores\")[5]) \\\n",
        "  # Apply other UDFs\n",
        "  df_input = df_input.withColumn(\"Scientific_Notation\", is_scientific_notation_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  df_input = df_input.withColumn(\"Thousand_Separator\", thousand_separator_difference_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  df_input = df_input.withColumn(\"Leading_Zero\", leading_zero_check_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  df_input = df_input.withColumn(\"Rounded_Off\", are_numbers_effectively_equal_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  df_input = df_input.withColumn(\"Currency_Diff\", detect_currency_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  df_input = df_input.withColumn(\"Negative_Check\", negative_check_udf(col(\"Source\"), col(\"Destination\")))\n",
        "  from pyspark.sql.functions import col, when\n",
        "\n",
        "  # Convert Boolean columns to integer\n",
        "  columns_to_convert = ['Scientific_Notation',\n",
        "  'Thousand_Separator',\n",
        "  'Rounded_Off',\n",
        "  'Leading_Zero',\n",
        "  'Currency_Diff',\n",
        "  'Negative_Check',]\n",
        "  for column in columns_to_convert:\n",
        "      df_input = df_input.withColumn(column, when(col(column), 1).otherwise(0))\n",
        "\n",
        "  # Select relevant features\n",
        "  feature_columns = ['Scientific_Notation',\n",
        "  'Thousand_Separator',\n",
        "  'Rounded_Off',\n",
        "  'Leading_Zero',\n",
        "  'Currency_Diff',\n",
        "  'Negative_Check',\n",
        "  'Case_Sensitive_Score',\n",
        "  'Case_Insensitive_Score',\n",
        "  'Case_Sensitivity_Diff',\n",
        "  'Special_Character_Score',\n",
        "  'Special_Character_Diff',\n",
        "  'Space_diff',\n",
        "  'space_score',]\n",
        "\n",
        "  # List of columns to cast\n",
        "  columns_to_cast = ['Scientific_Notation',\n",
        "  'Thousand_Separator',\n",
        "  'Rounded_Off',\n",
        "  'Leading_Zero',\n",
        "  'Currency_Diff',\n",
        "  'Negative_Check',\n",
        "  'Case_Sensitive_Score',\n",
        "  'Case_Insensitive_Score',\n",
        "  'Case_Sensitivity_Diff',\n",
        "  'Special_Character_Score',\n",
        "  'Special_Character_Diff',\n",
        "  'Space_diff',\n",
        "  'space_score']\n",
        "\n",
        "  # Cast each column to Integer\n",
        "  for col_name in columns_to_cast:\n",
        "      df_input = df_input.withColumn(col_name, col(col_name).cast(\"int\"))\n",
        "  assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "  df_input = assembler.transform(df_input)\n",
        "  return df_input"
      ],
      "metadata": {
        "id": "oSGqlv8FEKAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Text input fields for the source and destination strings\n",
        "text_source = widgets.Text(value='srinivas', description='Source:', placeholder='Type something')\n",
        "text_destination = widgets.Text(value='sr in iva', description='Destination:', placeholder='Type something')\n",
        "\n",
        "# Button to trigger the prediction\n",
        "button_predict = widgets.Button(description='Predict')\n",
        "\n",
        "# Output widget to display results\n",
        "output = widgets.Output()\n",
        "\n",
        "# Function to handle button click event\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        # Assuming 'model' and 'prepare_features' are defined and loaded properly\n",
        "        word1 = text_source.value\n",
        "        word2 = text_destination.value\n",
        "        # Prepare features and predict\n",
        "        df_input = prepare_features(word1, word2)  # You need to implement this function\n",
        "        prediction = model.transform(df_input).select(\"prediction\").collect()[0][0]\n",
        "        # Map prediction index to label\n",
        "        labels = {\n",
        "            0: 'Case Sensitivity',\n",
        "            1: 'Extra Space Issues',\n",
        "            2: 'Special Character Differences',\n",
        "            3: 'Rounded Off Numbers',\n",
        "            4: 'Currency Symbol Difference',\n",
        "            5: 'Leading Zero Issue',\n",
        "            6: 'Negative vs Positive',\n",
        "            7: 'Scientific Notation Difference',\n",
        "            8: 'Thousands Separator Difference',\n",
        "            9: 'No Match'\n",
        "        }\n",
        "        print(f'Prediction: {labels[prediction]}')\n",
        "\n",
        "# Attach the button click event\n",
        "button_predict.on_click(on_button_clicked)\n",
        "\n",
        "# Display widgets\n",
        "widgets.VBox([text_source, text_destination, button_predict, output])\n"
      ],
      "metadata": {
        "id": "WAt3QzVpYDX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ybCdrs-UGRRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JrmOP7EDGRVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4z2AlsnGRZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eCOT3y6PGRf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Index 0 corresponds to label 'Case Sensitivity'\n",
        "Index 1 corresponds to label 'Extra Space Issues'\n",
        "Index 2 corresponds to label 'Special Character Differences'\n",
        "Index 3 corresponds to label 'Rounded Off Numbers'\n",
        "Index 4 corresponds to label 'Currency Symbol Difference'\n",
        "Index 5 corresponds to label 'Leading Zero Issue'\n",
        "Index 6 corresponds to label 'Negative vs Positive'\n",
        "Index 7 corresponds to label 'Scientific Notation Difference'\n",
        "Index 8 corresponds to label 'Thousands Separator Difference'\n",
        "Index 9 corresponds to label 'No Match'"
      ],
      "metadata": {
        "id": "35IB3qyoYDbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrHXP5ItYDhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rFOSRWKHYDoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhaDiaWxYDuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4N_fsgFYD0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_udf = udf(get_fuzzy_scores, VectorUDT())\n",
        "is_scientific_notation_udf = udf(scientific_notation_with_tolerance, BooleanType())\n",
        "thousand_separator_difference_udf = udf(thousand_separator_difference, BooleanType())\n",
        "leading_zero_check_udf = udf(leading_zero_check, BooleanType())\n",
        "are_numbers_effectively_equal_udf = udf(are_numbers_effectively_equal, BooleanType())\n",
        "detect_currency_udf = udf(detect_currency, BooleanType())\n",
        "negative_check_udf = udf(negative_check, BooleanType())"
      ],
      "metadata": {
        "id": "sytsV7XAMWUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input words\n",
        "word1 = \"srinvas\"\n",
        "word2 = \"sr invas\"\n",
        "\n",
        "# Convert input into DataFrame for prediction\n",
        "df_input = spark.createDataFrame([(word1, word2)], [\"Source\", \"Destination\"])\n",
        "df_input = df_input.withColumn(\"features\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))"
      ],
      "metadata": {
        "id": "6Wxx0rEhMWW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_input = df_input.withColumn(\"Scientific_Notation\", is_scientific_notation_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Thousand_Separator\", thousand_separator_difference_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Leading_Zero\", leading_zero_check_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Rounded_Off\", are_numbers_effectively_equal_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Currency_Difference\", detect_currency_udf(col(\"Source\"), col(\"Destination\")))\n",
        "df_input = df_input.withColumn(\"Negative_Check\", negative_check_udf(col(\"Source\"), col(\"Destination\")))\n"
      ],
      "metadata": {
        "id": "j0qTWoreMWaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6aB-gxOMWj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rHlNfOBCMWm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bl_IF2lzMWqq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}