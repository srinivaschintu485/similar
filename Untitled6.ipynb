{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIqoEw67bTJJ",
        "outputId": "e84461e9-8caf-47d8-99c5-9bfceddb5e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing: 'abc' vs. 'abc'\n",
            "  Fuzz Ratio: 100.0\n",
            "  Fuzz Partial Ratio: 100.0\n",
            "  Fuzz Token Sort Ratio: 100.0\n",
            "  Fuzz Token Set Ratio: 100.0\n",
            "--------------------------------------------------\n",
            "Comparing: 'abc' vs. 'ABC'\n",
            "  Fuzz Ratio: 0.0\n",
            "  Fuzz Partial Ratio: 0.0\n",
            "  Fuzz Token Sort Ratio: 0.0\n",
            "  Fuzz Token Set Ratio: 0.0\n",
            "--------------------------------------------------\n",
            "Comparing: 'ABC' vs. 'ABC'\n",
            "  Fuzz Ratio: 100.0\n",
            "  Fuzz Partial Ratio: 100.0\n",
            "  Fuzz Token Sort Ratio: 100.0\n",
            "  Fuzz Token Set Ratio: 100.0\n",
            "--------------------------------------------------\n",
            "Comparing: 'abC' vs. 'Abc'\n",
            "  Fuzz Ratio: 33.333333333333336\n",
            "  Fuzz Partial Ratio: 40.0\n",
            "  Fuzz Token Sort Ratio: 33.333333333333336\n",
            "  Fuzz Token Set Ratio: 33.33333333333333\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from rapidfuzz import fuzz\n",
        "\n",
        "# Define string pairs\n",
        "string_pairs = [\n",
        "    (\"abc\", \"abc\"),\n",
        "    (\"abc\", \"ABC\"),\n",
        "    (\"ABC\", \"ABC\"),\n",
        "    (\"abC\", \"Abc\")\n",
        "]\n",
        "\n",
        "# Compute different fuzzy matching scores\n",
        "for str1, str2 in string_pairs:\n",
        "    print(f\"Comparing: '{str1}' vs. '{str2}'\")\n",
        "    print(f\"  Fuzz Ratio: {fuzz.ratio(str1, str2)}\")\n",
        "    print(f\"  Fuzz Partial Ratio: {fuzz.partial_ratio(str1, str2)}\")\n",
        "    print(f\"  Fuzz Token Sort Ratio: {fuzz.token_sort_ratio(str1, str2)}\")\n",
        "    print(f\"  Fuzz Token Set Ratio: {fuzz.token_set_ratio(str1, str2)}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import fuzz\n",
        "\n",
        "def detect_case_sensitivity(str1, str2, threshold=10):\n",
        "    \"\"\"\n",
        "    Determines if a record is case-sensitive based on fuzzy matching scores.\n",
        "\n",
        "    :param str1: First input string\n",
        "    :param str2: Second input string\n",
        "    :param threshold: Difference threshold to classify case sensitivity\n",
        "    :return: Dictionary with case sensitivity classification\n",
        "    \"\"\"\n",
        "    # Compute fuzzy scores with case sensitivity\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "\n",
        "    # Compute fuzzy scores without case sensitivity (convert to lowercase)\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "\n",
        "    # Compute the difference\n",
        "    score_difference = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    # If difference is above a threshold, it's case-sensitive\n",
        "    is_case_sensitive = score_difference > threshold\n",
        "\n",
        "    return {\n",
        "        \"String 1\": str1,\n",
        "        \"String 2\": str2,\n",
        "        \"Case-Sensitive Score\": case_sensitive_score,\n",
        "        \"Case-Insensitive Score\": case_insensitive_score,\n",
        "        \"Score Difference\": score_difference,\n",
        "        \"Case Sensitivity Detected\": is_case_sensitive\n",
        "    }\n",
        "\n",
        "# Define test cases\n",
        "string_pairs = [\n",
        "    (\"abc\", \"abc\"),\n",
        "    (\"abc\", \"ABC\"),\n",
        "    (\"ABC\", \"ABC\"),\n",
        "    (\"abC\", \"Abc\"),\n",
        "    (\"DataScience\", \"Datascience\"),\n",
        "    (\"John Doe\", \"john doe\")\n",
        "]\n",
        "\n",
        "# Run the detection\n",
        "for str1, str2 in string_pairs:\n",
        "    result = detect_case_sensitivity(str1, str2)\n",
        "    print(f\"Comparing: '{str1}' vs. '{str2}'\")\n",
        "    print(f\"  Case-Sensitive Score: {result['Case-Sensitive Score']}\")\n",
        "    print(f\"  Case-Insensitive Score: {result['Case-Insensitive Score']}\")\n",
        "    print(f\"  Score Difference: {result['Score Difference']}\")\n",
        "    print(f\"  Case Sensitivity Detected: {result['Case Sensitivity Detected']}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0OYmfdBcxhR",
        "outputId": "a04f0623-321d-4078-ac9b-5a8d8481a8cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing: 'abc' vs. 'abc'\n",
            "  Case-Sensitive Score: 100.0\n",
            "  Case-Insensitive Score: 100.0\n",
            "  Score Difference: 0.0\n",
            "  Case Sensitivity Detected: False\n",
            "--------------------------------------------------\n",
            "Comparing: 'abc' vs. 'ABC'\n",
            "  Case-Sensitive Score: 0.0\n",
            "  Case-Insensitive Score: 100.0\n",
            "  Score Difference: 100.0\n",
            "  Case Sensitivity Detected: True\n",
            "--------------------------------------------------\n",
            "Comparing: 'ABC' vs. 'ABC'\n",
            "  Case-Sensitive Score: 100.0\n",
            "  Case-Insensitive Score: 100.0\n",
            "  Score Difference: 0.0\n",
            "  Case Sensitivity Detected: False\n",
            "--------------------------------------------------\n",
            "Comparing: 'abC' vs. 'Abc'\n",
            "  Case-Sensitive Score: 33.333333333333336\n",
            "  Case-Insensitive Score: 100.0\n",
            "  Score Difference: 66.66666666666666\n",
            "  Case Sensitivity Detected: True\n",
            "--------------------------------------------------\n",
            "Comparing: 'DataScience' vs. 'Datascience'\n",
            "  Case-Sensitive Score: 90.9090909090909\n",
            "  Case-Insensitive Score: 100.0\n",
            "  Score Difference: 9.090909090909093\n",
            "  Case Sensitivity Detected: False\n",
            "--------------------------------------------------\n",
            "Comparing: 'John Doe' vs. 'john doe'\n",
            "  Case-Sensitive Score: 75.0\n",
            "  Case-Insensitive Score: 100.0\n",
            "  Score Difference: 25.0\n",
            "  Case Sensitivity Detected: True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "def preprocess_text(text, mode):\n",
        "    \"\"\"\n",
        "    Apply different types of text normalization based on mode.\n",
        "    \"\"\"\n",
        "    if mode == \"lowercase\":\n",
        "        return text.lower()\n",
        "    elif mode == \"remove_punctuation\":\n",
        "        return re.sub(r'[^\\w\\s]', '', text)\n",
        "    elif mode == \"normalize_spaces\":\n",
        "        return re.sub(r'\\s+', ' ', text).strip()\n",
        "    elif mode == \"expand_abbreviations\":\n",
        "        abbreviations = {\"corp.\": \"corporation\", \"ltd.\": \"limited\", \"inc.\": \"incorporated\"}\n",
        "        words = text.split()\n",
        "        expanded = [abbreviations.get(word.lower(), word) for word in words]\n",
        "        return \" \".join(expanded)\n",
        "    return text\n",
        "\n",
        "def classify_difference(str1, str2):\n",
        "    \"\"\"\n",
        "    Classify the type of difference between two strings.\n",
        "    \"\"\"\n",
        "    categories = {\n",
        "        \"Case Sensitivity\": preprocess_text(str1, \"lowercase\"),\n",
        "        \"Special Character Differences\": preprocess_text(str1, \"remove_punctuation\"),\n",
        "        \"Extra Space Issues\": preprocess_text(str1, \"normalize_spaces\"),\n",
        "        \"Abbreviation vs. Full Form\": preprocess_text(str1, \"expand_abbreviations\"),\n",
        "    }\n",
        "\n",
        "    differences = {}\n",
        "    for category, transformed_str in categories.items():\n",
        "        score = fuzz.ratio(transformed_str, str2)\n",
        "        differences[category] = score\n",
        "\n",
        "    # Identify the category with the highest impact (lowest score means most difference)\n",
        "    classified_category = min(differences, key=differences.get)\n",
        "\n",
        "    return {\"String 1\": str1, \"String 2\": str2, \"Classification\": classified_category, \"Scores\": differences}\n",
        "\n",
        "# Test cases\n",
        "string_pairs = [\n",
        "    (\"Corp.\", \"Corporation\"),  # Abbreviation\n",
        "    (\"abc\", \"ABC\"),  # Case Sensitivity\n",
        "    (\"AT&T\", \"ATT\"),  # Special Character Differences\n",
        "    (\"XYZ Ltd.\", \"XYZ    Ltd.\")  # Extra Spaces\n",
        "]\n",
        "\n",
        "# Run classification on test cases\n",
        "for str1, str2 in string_pairs:\n",
        "    result = classify_difference(str1, str2)\n",
        "    print(f\"Comparing: '{str1}' vs. '{str2}'\")\n",
        "    print(f\"  Classified Difference: {result['Classification']}\")\n",
        "    print(f\"  Score Breakdown: {result['Scores']}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGASw8nrdelS",
        "outputId": "914997d3-219a-4129-c96d-ff4f671185e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing: 'Corp.' vs. 'Corporation'\n",
            "  Classified Difference: Case Sensitivity\n",
            "  Score Breakdown: {'Case Sensitivity': 37.5, 'Special Character Differences': 53.333333333333336, 'Extra Space Issues': 50.0, 'Abbreviation vs. Full Form': 90.9090909090909}\n",
            "--------------------------------------------------\n",
            "Comparing: 'abc' vs. 'ABC'\n",
            "  Classified Difference: Case Sensitivity\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 0.0, 'Extra Space Issues': 0.0, 'Abbreviation vs. Full Form': 0.0}\n",
            "--------------------------------------------------\n",
            "Comparing: 'AT&T' vs. 'ATT'\n",
            "  Classified Difference: Case Sensitivity\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 100.0, 'Extra Space Issues': 85.71428571428572, 'Abbreviation vs. Full Form': 85.71428571428572}\n",
            "--------------------------------------------------\n",
            "Comparing: 'XYZ Ltd.' vs. 'XYZ    Ltd.'\n",
            "  Classified Difference: Case Sensitivity\n",
            "  Score Breakdown: {'Case Sensitivity': 42.10526315789473, 'Special Character Differences': 77.77777777777779, 'Extra Space Issues': 84.21052631578947, 'Abbreviation vs. Full Form': 54.54545454545454}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSBRtF_yfZ2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IlmtS3ZfZ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "def classify_difference(str1, str2, threshold=10):\n",
        "    \"\"\"\n",
        "    Classifies the type of difference between two strings.\n",
        "\n",
        "    :param str1: First string\n",
        "    :param str2: Second string\n",
        "    :param threshold: Minimum score difference to classify a change\n",
        "    :return: Classification and score breakdown\n",
        "    \"\"\"\n",
        "    # Compute original fuzzy score\n",
        "    original_score = fuzz.ratio(str1, str2)\n",
        "\n",
        "    # Compute case-insensitive fuzzy score\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = original_score - case_insensitive_score\n",
        "\n",
        "    # Compute score after removing special characters\n",
        "    str1_clean = re.sub(r'[^\\w\\s]', '', str1)\n",
        "    str2_clean = re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = original_score - special_char_score\n",
        "\n",
        "    # Compute score after normalizing spaces\n",
        "    str1_space_norm = ' '.join(str1.split())\n",
        "    str2_space_norm = ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = original_score - space_score\n",
        "\n",
        "    # Compute token set ratio for abbreviation detection\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = original_score - token_score\n",
        "\n",
        "    # Determine the major difference\n",
        "    max_diff = max(abs(case_sensitivity_diff), abs(special_char_diff), abs(space_diff), abs(abbreviation_diff))\n",
        "\n",
        "    if abs(case_sensitivity_diff) > threshold:\n",
        "        classified_difference = \"Case Sensitivity\"\n",
        "    elif abs(special_char_diff) > threshold:\n",
        "        classified_difference = \"Special Character Differences\"\n",
        "    elif abs(space_diff) > threshold:\n",
        "        classified_difference = \"Extra Space Issues\"\n",
        "    elif abs(abbreviation_diff) > threshold:\n",
        "        classified_difference = \"Abbreviation vs. Full Form\"\n",
        "    else:\n",
        "        classified_difference = \"No Significant Difference\"\n",
        "\n",
        "    # Score breakdown\n",
        "    score_breakdown = {\n",
        "        \"Case Sensitivity\": abs(case_sensitivity_diff),\n",
        "        \"Special Character Differences\": abs(special_char_diff),\n",
        "        \"Extra Space Issues\": abs(space_diff),\n",
        "        \"Abbreviation vs. Full Form\": abs(abbreviation_diff)\n",
        "    }\n",
        "\n",
        "    return classified_difference, score_breakdown\n",
        "\n",
        "# Test cases\n",
        "string_pairs = [\n",
        "    (\"abc\", \"ABC\"),\n",
        "    (\"AT&T\", \"ATT\"),\n",
        "    (\"XYZ Ltd.\", \"XYZ    Ltd.\"),\n",
        "    (\"Corp.\", \"Corporation\"),\n",
        "    (\"Data-Science\", \"Data Science\"),\n",
        "    (\"Hello  World\", \"Hello World\")\n",
        "]\n",
        "\n",
        "# Run classification\n",
        "for str1, str2 in string_pairs:\n",
        "    classified_diff, score_breakdown = classify_difference(str1, str2)\n",
        "    print(f\"Comparing: '{str1}' vs. '{str2}'\")\n",
        "    print(f\"  Classified Difference: {classified_diff}\")\n",
        "    print(f\"  Score Breakdown: {score_breakdown}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv8Nshy7fZ_l",
        "outputId": "74843c64-8210-4481-a6ce-3f708c736a00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing: 'abc' vs. 'ABC'\n",
            "  Classified Difference: Case Sensitivity\n",
            "  Score Breakdown: {'Case Sensitivity': 100.0, 'Special Character Differences': 0.0, 'Extra Space Issues': 0.0, 'Abbreviation vs. Full Form': 0.0}\n",
            "--------------------------------------------------\n",
            "Comparing: 'AT&T' vs. 'ATT'\n",
            "  Classified Difference: Special Character Differences\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 14.285714285714278, 'Extra Space Issues': 0.0, 'Abbreviation vs. Full Form': 1.4210854715202004e-14}\n",
            "--------------------------------------------------\n",
            "Comparing: 'XYZ Ltd.' vs. 'XYZ    Ltd.'\n",
            "  Classified Difference: Extra Space Issues\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 1.8575851393188856, 'Extra Space Issues': 15.789473684210535, 'Abbreviation vs. Full Form': 15.789473684210535}\n",
            "--------------------------------------------------\n",
            "Comparing: 'Corp.' vs. 'Corporation'\n",
            "  Classified Difference: No Significant Difference\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 3.3333333333333357, 'Extra Space Issues': 0.0, 'Abbreviation vs. Full Form': 0.0}\n",
            "--------------------------------------------------\n",
            "Comparing: 'Data-Science' vs. 'Data Science'\n",
            "  Classified Difference: No Significant Difference\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 3.9855072463768266, 'Extra Space Issues': 0.0, 'Abbreviation vs. Full Form': 1.4210854715202004e-14}\n",
            "--------------------------------------------------\n",
            "Comparing: 'Hello  World' vs. 'Hello World'\n",
            "  Classified Difference: No Significant Difference\n",
            "  Score Breakdown: {'Case Sensitivity': 0.0, 'Special Character Differences': 0.0, 'Extra Space Issues': 4.347826086956516, 'Abbreviation vs. Full Form': 4.347826086956516}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "import pandas as pd\n",
        "\n",
        "def classify_difference(str1, str2, threshold=10):\n",
        "    \"\"\"\n",
        "    Classifies the type of difference between two strings and prints scores.\n",
        "\n",
        "    :param str1: First string\n",
        "    :param str2: Second string\n",
        "    :param threshold: Minimum score difference to classify a change\n",
        "    :return: Classification and score breakdown\n",
        "    \"\"\"\n",
        "    # Compute original (case-sensitive) fuzzy score\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "\n",
        "    # Compute case-insensitive fuzzy score\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    # Compute score after removing special characters\n",
        "    str1_clean = re.sub(r'[^\\w\\s]', '', str1)\n",
        "    str2_clean = re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    # Compute score after normalizing spaces\n",
        "    str1_space_norm = ' '.join(str1.split())\n",
        "    str2_space_norm = ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)\n",
        "\n",
        "    # Compute token set ratio for abbreviation detection\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = abs(case_sensitive_score - token_score)\n",
        "\n",
        "    # Determine the major difference\n",
        "    max_diff = max(case_sensitivity_diff, special_char_diff, space_diff, abbreviation_diff)\n",
        "\n",
        "    if case_sensitivity_diff > threshold:\n",
        "        classified_difference = \"Case Sensitivity\"\n",
        "    elif special_char_diff > threshold:\n",
        "        classified_difference = \"Special Character Differences\"\n",
        "    elif space_diff > threshold:\n",
        "        classified_difference = \"Extra Space Issues\"\n",
        "    elif abbreviation_diff > threshold:\n",
        "        classified_difference = \"Abbreviation vs. Full Form\"\n",
        "    else:\n",
        "        classified_difference = \"No Significant Difference\"\n",
        "\n",
        "    # Score breakdown\n",
        "    score_breakdown = {\n",
        "        \"Case Sensitivity\": case_sensitivity_diff,\n",
        "        \"Special Character Differences\": special_char_diff,\n",
        "        \"Extra Space Issues\": space_diff,\n",
        "        \"Abbreviation vs. Full Form\": abbreviation_diff\n",
        "    }\n",
        "\n",
        "    return classified_difference, case_sensitive_score, case_insensitive_score, score_breakdown\n",
        "\n",
        "# Test cases\n",
        "string_pairs = [\n",
        "    (\"abc\", \"ABC\"),\n",
        "    (\"AT&T\", \"ATT\"),\n",
        "    (\"XYZ Ltd.\", \"XYZ    Ltd.\"),\n",
        "    (\"Corp.\", \"Corporation\"),\n",
        "    (\"Data-Science\", \"Data Science\"),\n",
        "    (\"Hello  World\", \"Hello World\")\n",
        "]\n",
        "\n",
        "# Collect results\n",
        "results = []\n",
        "for str1, str2 in string_pairs:\n",
        "    classified_diff, case_sensitive_score, case_insensitive_score, score_breakdown = classify_difference(str1, str2)\n",
        "    results.append({\n",
        "        \"String 1\": str1,\n",
        "        \"String 2\": str2,\n",
        "        \"Case-Sensitive Score\": case_sensitive_score,\n",
        "        \"Case-Insensitive Score\": case_insensitive_score,\n",
        "        \"Classified Difference\": classified_diff,\n",
        "        **score_breakdown\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgq_MorOgv-D",
        "outputId": "1d1cd4c7-dc2d-4b16-b07f-89c402253f35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       String 1      String 2  Case-Sensitive Score  Case-Insensitive Score  \\\n",
            "0           abc           ABC              0.000000              100.000000   \n",
            "1          AT&T           ATT             85.714286               85.714286   \n",
            "2      XYZ Ltd.   XYZ    Ltd.             84.210526               84.210526   \n",
            "3         Corp.   Corporation             50.000000               50.000000   \n",
            "4  Data-Science  Data Science             91.666667               91.666667   \n",
            "5  Hello  World   Hello World             95.652174               95.652174   \n",
            "\n",
            "           Classified Difference  Case Sensitivity  \\\n",
            "0               Case Sensitivity             100.0   \n",
            "1  Special Character Differences               0.0   \n",
            "2             Extra Space Issues               0.0   \n",
            "3      No Significant Difference               0.0   \n",
            "4      No Significant Difference               0.0   \n",
            "5      No Significant Difference               0.0   \n",
            "\n",
            "   Special Character Differences  Extra Space Issues  \\\n",
            "0                       0.000000            0.000000   \n",
            "1                      14.285714            0.000000   \n",
            "2                       1.857585           15.789474   \n",
            "3                       3.333333            0.000000   \n",
            "4                       3.985507            0.000000   \n",
            "5                       0.000000            4.347826   \n",
            "\n",
            "   Abbreviation vs. Full Form  \n",
            "0                0.000000e+00  \n",
            "1                1.421085e-14  \n",
            "2                1.578947e+01  \n",
            "3                0.000000e+00  \n",
            "4                1.421085e-14  \n",
            "5                4.347826e+00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "import pandas as pd\n",
        "\n",
        "def classify_difference(str1, str2, threshold=10):\n",
        "    \"\"\"\n",
        "    Classifies the type of difference between two strings and prints scores.\n",
        "\n",
        "    :param str1: First string\n",
        "    :param str2: Second string\n",
        "    :param threshold: Minimum score difference to classify a change\n",
        "    :return: Classification and score breakdown\n",
        "    \"\"\"\n",
        "    # Compute original (case-sensitive) fuzzy score\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "\n",
        "    # Compute case-insensitive fuzzy score\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    # Compute score after removing special characters\n",
        "    str1_clean = re.sub(r'[^\\w\\s]', '', str1)\n",
        "    str2_clean = re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    # Compute score after normalizing spaces\n",
        "    str1_space_norm = ' '.join(str1.split())\n",
        "    str2_space_norm = ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)\n",
        "\n",
        "    # Compute token set ratio for abbreviation detection\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = abs(case_sensitive_score - token_score)\n",
        "\n",
        "    # Determine the major difference\n",
        "    max_diff = max(case_sensitivity_diff, special_char_diff, space_diff, abbreviation_diff)\n",
        "\n",
        "    if case_sensitivity_diff > threshold:\n",
        "        classified_difference = \"Case Sensitivity\"\n",
        "    elif special_char_diff > threshold:\n",
        "        classified_difference = \"Special Character Differences\"\n",
        "    elif space_diff > threshold:\n",
        "        classified_difference = \"Extra Space Issues\"\n",
        "    elif abbreviation_diff > threshold:\n",
        "        classified_difference = \"Abbreviation vs. Full Form\"\n",
        "    else:\n",
        "        classified_difference = \"No Significant Difference\"\n",
        "\n",
        "    # Score breakdown\n",
        "    score_breakdown = {\n",
        "        \"Case Sensitivity\": case_sensitivity_diff,\n",
        "        \"Special Character Differences\": special_char_diff,\n",
        "        \"Extra Space Issues\": space_diff,\n",
        "        \"Abbreviation vs. Full Form\": abbreviation_diff\n",
        "    }\n",
        "\n",
        "    return classified_difference, case_sensitive_score, case_insensitive_score, score_breakdown\n",
        "\n",
        "# Test cases\n",
        "string_pairs = [\n",
        "    (\"abc\", \"ABC\"),\n",
        "    (\"AT&T\", \"ATT\"),\n",
        "    (\"XYZ Ltd.\", \"XYZ    Ltd.\"),\n",
        "    (\"Corp.\", \"Corporation\"),\n",
        "    (\"Data-Science\", \"Data Science\"),\n",
        "    (\"Hello  World\", \"Hello World\")\n",
        "]\n",
        "\n",
        "# Collect results\n",
        "results = []\n",
        "for str1, str2 in string_pairs:\n",
        "    classified_diff, case_sensitive_score, case_insensitive_score, score_breakdown = classify_difference(str1, str2)\n",
        "    results.append({\n",
        "        \"String 1\": str1,\n",
        "        \"String 2\": str2,\n",
        "        \"Case-Sensitive Score\": case_sensitive_score,\n",
        "        \"Case-Insensitive Score\": case_insensitive_score,\n",
        "        \"Classified Difference\": classified_diff,\n",
        "        **score_breakdown\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save to Excel\n",
        "file_path = \"/content/sample_data/Fuzzy_Matching_Analysis.xlsx\"\n",
        "df_results.to_excel(file_path, index=False)\n",
        "\n",
        "print(f\"Excel file saved: {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVYeSy2JfaCy",
        "outputId": "929177e4-d932-4c33-94c7-b48deff32ba1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel file saved: /content/sample_data/Fuzzy_Matching_Analysis.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "nJ4F2vS7hVXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark rapidfuzz openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3jcIRhFfaF7",
        "outputId": "3cfb9e48-d145-4e36-c9a0-ca1b80622ef9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (3.12.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Excel file\n",
        "df = pd.read_excel(\"/content/Dataset.xlsx\")\n",
        "\n",
        "# Save as CSV\n",
        "df.to_csv(\"/content/Fuzzy_Matching_Dataset.csv\", index=False)\n",
        "print(\"Excel converted to CSV successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NPXQIimp_vS",
        "outputId": "46df0192-d99a-4e20-843a-b8a5878cb6e0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel converted to CSV successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType, DoubleType\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"FuzzyMatching\").getOrCreate()\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"/content/Fuzzy_Matching_Dataset.csv\"\n",
        "df_pyspark = spark.read.csv(dataset_path,header=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "A6tcMYVKfaJI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWd6gx12sA2M",
        "outputId": "e29314bc-e4a3-4e77-d358-f069fc0e77f2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------------+\n",
            "|              Source|         Destination|           Label|\n",
            "+--------------------+--------------------+----------------+\n",
            "|  Big Data Analytics|  BIG DATA ANALYTICS|Case Sensitivity|\n",
            "|Business Intellig...|business intellig...|Case Sensitivity|\n",
            "|  Big Data Analytics|  big data analytics|Case Sensitivity|\n",
            "|  Geospatial Studies|  GEOSPATIAL STUDIES|Case Sensitivity|\n",
            "|  Big Data Analytics|  BIG DATA ANALYTICS|Case Sensitivity|\n",
            "|      Cyber Security|      cyber security|Case Sensitivity|\n",
            "| University Research| UNIVERSITY RESEARCH|Case Sensitivity|\n",
            "|    Machine Learning|    MACHINE LEARNING|Case Sensitivity|\n",
            "|Artificial Intell...|artificial intell...|Case Sensitivity|\n",
            "|        Data Science|        DATA SCIENCE|Case Sensitivity|\n",
            "|  Geospatial Studies|  GEOSPATIAL STUDIES|Case Sensitivity|\n",
            "|        Data Science|        DATA SCIENCE|Case Sensitivity|\n",
            "|     Cloud Computing|     CLOUD COMPUTING|Case Sensitivity|\n",
            "|Business Intellig...|BUSINESS INTELLIG...|Case Sensitivity|\n",
            "|     Cloud Computing|     CLOUD COMPUTING|Case Sensitivity|\n",
            "|  Geospatial Studies|  GEOSPATIAL STUDIES|Case Sensitivity|\n",
            "|Business Intellig...|BUSINESS INTELLIG...|Case Sensitivity|\n",
            "|    Machine Learning|    machine learning|Case Sensitivity|\n",
            "|Business Intellig...|BUSINESS INTELLIG...|Case Sensitivity|\n",
            "|     Cloud Computing|     CLOUD COMPUTING|Case Sensitivity|\n",
            "+--------------------+--------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define fuzzy matching functions\n",
        "def get_fuzzy_scores(str1, str2):\n",
        "    \"\"\" Compute various fuzzy matching scores between two strings. \"\"\"\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    str1_clean, str2_clean = re.sub(r'[^\\w\\s]', '', str1), re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    str1_space_norm, str2_space_norm = ' '.join(str1.split()), ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)\n",
        "\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = abs(case_sensitive_score - token_score)\n",
        "\n",
        "    return (case_sensitive_score, case_insensitive_score, case_sensitivity_diff,\n",
        "            special_char_diff, space_diff, abbreviation_diff)\n",
        "\n",
        "# Register UDFs\n",
        "fuzzy_udf = udf(lambda str1, str2: get_fuzzy_scores(str1, str2),\n",
        "                \"array<double>\")\n",
        "\n",
        "# Apply fuzzy matching functions\n",
        "df_pyspark = df_pyspark.withColumn(\"Fuzzy Scores\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))\n",
        "\n",
        "# Extract individual scores\n",
        "df_pyspark = df_pyspark.withColumn(\"Case-Sensitive Score\", col(\"Fuzzy Scores\")[0]) \\\n",
        "                       .withColumn(\"Case-Insensitive Score\", col(\"Fuzzy Scores\")[1]) \\\n",
        "                       .withColumn(\"Case Sensitivity Diff\", col(\"Fuzzy Scores\")[2]) \\\n",
        "                       .withColumn(\"Special Character Diff\", col(\"Fuzzy Scores\")[3]) \\\n",
        "                       .withColumn(\"Extra Space Diff\", col(\"Fuzzy Scores\")[4]) \\\n",
        "                       .drop(\"Fuzzy Scores\")\n",
        "                      #  .withColumn(\"Abbreviation Diff\", col(\"Fuzzy Scores\")[5]) \\\n",
        "\n",
        "\n",
        "# Save results to an Excel file\n",
        "output_path = \"Scored_Fuzzy_Matching_Analysis.xlsx\"\n",
        "df_pyspark.toPandas().to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"Scored dataset saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfaI9SBHsA8q",
        "outputId": "f735d0a6-55fb-44e8-806a-6ed690559da3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored dataset saved to: Scored_Fuzzy_Matching_Analysis.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZL3dIx2efaMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, StringType\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "kvDfENEv2-LL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Excel file\n",
        "df = pd.read_excel(\"/content/Scored_Fuzzy_Matching_Analysis.xlsx\")\n",
        "\n",
        "# Save as CSV\n",
        "df.to_csv(\"/content/train.csv\", index=False)\n",
        "print(\"Excel converted to CSV successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM8jJUpd_Ira",
        "outputId": "a20b70fa-df4f-4104-d872-7a1ea05f55ac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel converted to CSV successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset_path = \"/content/train.csv\"\n",
        "df_pyspark = spark.read.csv(dataset_path,header=True)"
      ],
      "metadata": {
        "id": "0nsJdIbl_lyF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list the distinct values in Label\n",
        "df_pyspark.select(\"Label\").distinct().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqgpsMKC_mla",
        "outputId": "9ab20041-26a7-4505-9fad-f9f454ac16ff"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|Label                        |\n",
            "+-----------------------------+\n",
            "|Extra Space Issues           |\n",
            "|Special Character Differences|\n",
            "|Case Sensitivity             |\n",
            "+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(\"Label_Index\").distinct().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZdcqS5-Cfa5",
        "outputId": "1be27c48-098a-488c-afa8-243fd85254e9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|Label_Index|\n",
            "+-----------+\n",
            "|0.0        |\n",
            "|1.0        |\n",
            "|2.0        |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_pyspark = df_pyspark.filter(col(\"Label\") != \"Abbreviation vs. Full Form\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dtNDic41AdGY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iDUFad0AC88",
        "outputId": "c471d576-6e12-463e-ca51-855783f721df"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Label: string]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert categorical label (text) into numerical index\n",
        "indexer = StringIndexer(inputCol=\"Label\", outputCol=\"Label_Index\")\n",
        "df_pyspark = indexer.fit(df_pyspark).transform(df_pyspark)"
      ],
      "metadata": {
        "id": "3Xbo7z0pA0K6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features\n",
        "feature_columns = [\"Case Sensitivity Diff\", \"Special Character Diff\", \"Extra Space Diff\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
      ],
      "metadata": {
        "id": "3HlvobL2BLJS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to cast\n",
        "columns_to_cast = [\"Case Sensitivity Diff\", \"Special Character Diff\", \"Extra Space Diff\"]\n",
        "\n",
        "# Cast each column to Integer\n",
        "for col_name in columns_to_cast:\n",
        "    df_pyspark = df_pyspark.withColumn(col_name, col(col_name).cast(\"int\"))"
      ],
      "metadata": {
        "id": "Px4ThR9SBxXz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKu6R7eQBQYv",
        "outputId": "0c667e3f-0613-49c0-f41c-696984825309"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Source: string (nullable = true)\n",
            " |-- Destination: string (nullable = true)\n",
            " |-- Label: string (nullable = true)\n",
            " |-- Case-Sensitive Score: string (nullable = true)\n",
            " |-- Case-Insensitive Score: string (nullable = true)\n",
            " |-- Case Sensitivity Diff: integer (nullable = true)\n",
            " |-- Special Character Diff: integer (nullable = true)\n",
            " |-- Extra Space Diff: integer (nullable = true)\n",
            " |-- Label_Index: double (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = assembler.transform(df_pyspark)"
      ],
      "metadata": {
        "id": "sSU0WzoABM95"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "train_data, test_data = df_pyspark.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "mnr_6trRB2i_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the classifier (Random Forest)\n",
        "rf_classifier = RandomForestClassifier(labelCol=\"Label_Index\", featuresCol=\"features\", numTrees=50)\n",
        "model = rf_classifier.fit(train_data)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model using accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Label_Index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"✅ Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save trained model\n",
        "model.save(\"FuzzyMatching_RF_Model\")\n",
        "print(\"✅ Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd-sycOr2-Or",
        "outputId": "81e16c45-a755-4456-a858-8c2a0f99204f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Accuracy: 100.00%\n",
            "✅ Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG117yOq2-Rp",
        "outputId": "0d62ff14-0406-400f-eaba-ff5416973ff7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+----------------------+---------------------+----------------------+----------------+-----------+--------------+--------------+-------------+----------+\n",
            "|              Source|         Destination|               Label|Case-Sensitive Score|Case-Insensitive Score|Case Sensitivity Diff|Special Character Diff|Extra Space Diff|Label_Index|      features| rawPrediction|  probability|prediction|\n",
            "+--------------------+--------------------+--------------------+--------------------+----------------------+---------------------+----------------------+----------------+-----------+--------------+--------------+-------------+----------+\n",
            "|Artificial Intell...|A!r_ti$f-i@c.i!al...|Special Character...|   73.01587301587303|     73.01587301587303|                    0|                    24|               0|        2.0|[0.0,24.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A!rtif@icia-l# _I...|Special Character...|    79.3103448275862|      79.3103448275862|                    0|                    18|               0|        2.0|[0.0,18.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A#r%ti!f!ici-al $...|Special Character...|   73.01587301587303|     73.01587301587303|                    0|                    26|               0|        2.0|[0.0,26.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A#rt@i-ficial -I$...|Special Character...|   82.14285714285714|     82.14285714285714|                    0|                    15|               0|        2.0|[0.0,15.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A$rt.if@i.c#ial- ...|Special Character...|   80.70175438596492|     80.70175438596492|                    0|                    17|               0|        2.0|[0.0,17.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A%r@t$if_i-c&ial*...|Special Character...|   74.19354838709677|     74.19354838709677|                    0|                    21|               0|        2.0|[0.0,21.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A&r#t%i_fi#cia_l ...|Special Character...|    79.3103448275862|      79.3103448275862|                    0|                    12|               0|        2.0|[0.0,12.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A*rt@i#fi#ci@al I...|Special Character...|   85.18518518518519|     85.18518518518519|                    0|                    14|               0|        2.0|[0.0,14.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A.rtif_i$cial$ #I...|Special Character...|   77.96610169491525|     77.96610169491525|                    0|                    17|               0|        2.0|[0.0,17.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A@r-t_if_ic@ia&l ...|Special Character...|   83.63636363636364|     83.63636363636364|                    0|                    12|               0|        2.0|[0.0,12.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|A@rt%if$i#ci_al! ...|Special Character...|   77.96610169491525|     77.96610169491525|                    0|                    17|               0|        2.0|[0.0,17.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|ARTIFICIAL INTELL...|    Case Sensitivity|   13.04347826086957|                 100.0|                   86|                     0|               0|        0.0|[86.0,0.0,0.0]|[50.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|Artificial Intell...|Ar$t-ific#ial &I&...|Special Character...|   82.14285714285714|     82.14285714285714|                    0|                    15|               0|        2.0|[0.0,15.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|Artificial Intell...|Ar&ti_fici-a_l# I...|Special Character...|   80.70175438596492|     80.70175438596492|                    0|                    13|               0|        2.0|[0.0,13.0,0.0]|[0.0,0.0,50.0]|[0.0,0.0,1.0]|       2.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+----------------------+---------------------+----------------------+----------------+-----------+--------------+--------------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    str1_clean, str2_clean = re.sub(r'[^\\w\\s]', '', str1), re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    str1_space_norm, str2_space_norm = ' '.join(str1.split()), ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)"
      ],
      "metadata": {
        "id": "-4CbhLwE2-Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassificationModel\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"FuzzyMatchingPrediction\").getOrCreate()\n",
        "\n",
        "# Load trained model\n",
        "model_path = \"/content/FuzzyMatching_RF_Model\"\n",
        "model = RandomForestClassificationModel.load(model_path)\n",
        "\n",
        "# Function to compute fuzzy similarity scores\n",
        "def get_fuzzy_scores(str1, str2):\n",
        "    \"\"\" Compute fuzzy matching scores and return as a DenseVector for Spark MLlib. \"\"\"\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    str1_clean, str2_clean = re.sub(r'[^\\w\\s]', '', str1), re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    str1_space_norm, str2_space_norm = ' '.join(str1.split()), ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)\n",
        "\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = abs(case_sensitive_score - token_score)\n",
        "\n",
        "    # Ensure output is a DenseVector (needed for Spark ML)\n",
        "    return Vectors.dense([ case_sensitivity_diff,\n",
        "                          special_char_diff, space_diff])\n",
        "\n",
        "# UDF to convert string pairs into DenseVector for Spark ML\n",
        "fuzzy_udf = udf(get_fuzzy_scores, VectorUDT())\n",
        "\n",
        "# Example input words\n",
        "word1 = \"srin#^iVas\"\n",
        "word2 = \"SrinIvAS\"\n",
        "\n",
        "# Convert input into DataFrame for prediction\n",
        "df_input = spark.createDataFrame([(word1, word2)], [\"Source\", \"Destination\"])\n",
        "\n",
        "# Apply fuzzy matching function\n",
        "df_input = df_input.withColumn(\"features\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K_3RarWN2-X0"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassificationModel\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"FuzzyMatchingPrediction\").getOrCreate()\n",
        "\n",
        "# Load trained model\n",
        "model_path = \"/content/FuzzyMatching_RF_Model\"\n",
        "model = RandomForestClassificationModel.load(model_path)\n",
        "\n",
        "# Function to compute fuzzy similarity scores\n",
        "def get_fuzzy_scores(str1, str2):\n",
        "    \"\"\" Compute fuzzy matching scores and return as a DenseVector for Spark MLlib. \"\"\"\n",
        "    case_sensitive_score = fuzz.ratio(str1, str2)\n",
        "    case_insensitive_score = fuzz.ratio(str1.lower(), str2.lower())\n",
        "    case_sensitivity_diff = abs(case_sensitive_score - case_insensitive_score)\n",
        "\n",
        "    str1_clean, str2_clean = re.sub(r'[^\\w\\s]', '', str1), re.sub(r'[^\\w\\s]', '', str2)\n",
        "    special_char_score = fuzz.ratio(str1_clean, str2_clean)\n",
        "    special_char_diff = abs(case_sensitive_score - special_char_score)\n",
        "\n",
        "    str1_space_norm, str2_space_norm = ' '.join(str1.split()), ' '.join(str2.split())\n",
        "    space_score = fuzz.ratio(str1_space_norm, str2_space_norm)\n",
        "    space_diff = abs(case_sensitive_score - space_score)\n",
        "\n",
        "    token_score = fuzz.token_set_ratio(str1, str2)\n",
        "    abbreviation_diff = abs(case_sensitive_score - token_score)\n",
        "\n",
        "    # Ensure output is a DenseVector (needed for Spark ML)\n",
        "    return Vectors.dense([ case_sensitivity_diff,\n",
        "                          special_char_diff, space_diff])\n",
        "\n",
        "# UDF to convert string pairs into DenseVector for Spark ML\n",
        "fuzzy_udf = udf(get_fuzzy_scores, VectorUDT())\n",
        "\n",
        "# Example input words\n",
        "word1 = \"srin  vas\"\n",
        "word2 = \"srinivas\"\n",
        "\n",
        "# Convert input into DataFrame for prediction\n",
        "df_input = spark.createDataFrame([(word1, word2)], [\"Source\", \"Destination\"])\n",
        "\n",
        "# Apply fuzzy matching function\n",
        "df_input = df_input.withColumn(\"features\", fuzzy_udf(col(\"Source\"), col(\"Destination\")))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dGAUz62uL39A"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Case Sensitivity Diff|Special Character Diff|Extra Space Diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "LuB0AKCoKSBJ",
        "outputId": "27485abf-2f39-424c-b6e7-31d4136e1f38"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-114-3e5756aa53d2>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-114-3e5756aa53d2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Case Sensitivity Diff|Special Character Diff|Extra Space Diff\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_input.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4jhiKcvKIBX",
        "outputId": "ac0deb5c-a46c-439d-cbfb-e955ac0bbe73"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+--------------------+\n",
            "|   Source|Destination|            features|\n",
            "+---------+-----------+--------------------+\n",
            "|srin  vas|   srinivas|[0.0,0.0,5.147058...|\n",
            "+---------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "prediction = model.transform(df_input).select(\"prediction\").collect()[0][0]\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtvRJIVtLrMR",
        "outputId": "8b03a328-0608-41a4-db23-0b20a0e15c67"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map prediction index to label\n",
        "label_mapping = {\n",
        "    0.0: \"Extra Space Issues\",\n",
        "    1.0: \"Special Character Differences\",\n",
        "    2.0: \"Case Sensitivity\"\n",
        "}\n",
        "predicted_label = label_mapping.get(prediction, \"Unknown\")\n",
        "\n",
        "print(f\"Predicted Category: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wt1J0ZjKHVy",
        "outputId": "02f8c853-5337-48fe-c220-9aed230c6d12"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: Special Character Differences\n"
          ]
        }
      ]
    }
  ]
}