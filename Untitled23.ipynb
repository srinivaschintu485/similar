{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt2BMuIjJBdY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "107dNCzcJB_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPfFS_ivJCDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJbdABLPJCGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/Final_ML.csv\")  # Change to correct file path if needed\n",
        "\n",
        "# Define classification function\n",
        "def classify_data(value):\n",
        "    if isinstance(value, (int, float)) and not pd.isna(value):\n",
        "        return \"Numeric\"\n",
        "    elif isinstance(value, str):\n",
        "        if value.isalpha():\n",
        "            return \"Alphabetic\"\n",
        "        elif value.isalnum():\n",
        "            return \"Alphanumeric\"\n",
        "        elif any(c.isdigit() for c in value):\n",
        "            return \"Mixed\"\n",
        "        else:\n",
        "            return \"Other\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "# Apply classification to Source and Destination\n",
        "df['Source_Type'] = df['Source'].astype(str).apply(classify_data)\n",
        "df['Destination_Type'] = df['Destination'].astype(str).apply(classify_data)\n",
        "\n",
        "# Encode categorical features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for col in ['Source_Type', 'Destination_Type', 'Label']:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Feature Engineering\n",
        "df['Source_Length'] = df['Source'].astype(str).apply(len)\n",
        "df['Destination_Length'] = df['Destination'].astype(str).apply(len)\n",
        "df['Source_Digit_Count'] = df['Source'].astype(str).apply(lambda x: sum(c.isdigit() for c in x))\n",
        "df['Destination_Digit_Count'] = df['Destination'].astype(str).apply(lambda x: sum(c.isdigit() for c in x))\n",
        "df['Source_Alpha_Count'] = df['Source'].astype(str).apply(lambda x: sum(c.isalpha() for c in x))\n",
        "df['Destination_Alpha_Count'] = df['Destination'].astype(str).apply(lambda x: sum(c.isalpha() for c in x))\n",
        "df['Source_Has_Special'] = df['Source'].astype(str).apply(lambda x: int(any(not c.isalnum() for c in x)))\n",
        "df['Destination_Has_Special'] = df['Destination'].astype(str).apply(lambda x: int(any(not c.isalnum() for c in x)))\n",
        "\n",
        "# Features and target\n",
        "X = df[['Source_Type', 'Destination_Type', 'Source_Length', 'Destination_Length',\n",
        "        'Source_Digit_Count', 'Destination_Digit_Count', 'Source_Alpha_Count',\n",
        "        'Destination_Alpha_Count', 'Source_Has_Special', 'Destination_Has_Special']]\n",
        "y = df['Label']\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Neural Network model\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(len(y.unique()), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Neural Network Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "DkXrq_hzJCMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/dataset_alpha.csv\"  # Update this with your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Combine text columns\n",
        "text_features = df[['Source', 'Destination']].astype(str).agg(' '.join, axis=1)\n",
        "labels = df['Label'].astype(str)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize text features\n",
        "encoded_inputs = tokenizer(list(text_features), padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
        "\n",
        "# Extract BERT embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = bert_model(**encoded_inputs)\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # Use [CLS] token representation\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"BERT + Random Forest Classification Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "afSfsFlpTP6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VSMbjCwLTQrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the /content/extracted_data.csv file\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/extracted_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aDDA0EVbohHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add the null values with 0\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "KvlMXmh9ohK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To find the count of null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "jqXqTNslohN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the file\n",
        "df.to_csv('Final_ML.csv', index=False)"
      ],
      "metadata": {
        "id": "FZ1xv8xooqq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvnd5Al5oquI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRsYWW4goqxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rt-_lwgQoqz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BcY0q-A1oq2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07I_A8oxoq5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7DkVA9Wqoq8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpLRb2neoq_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KqoxqRI_orCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqIET04norE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8ELC0B-orH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DRULXMnXorLE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}